# Explore-Exploit Dilemma

- Epsilon-greedy
    (Eg. 5, 10%)

- Optimistic Initial Values
- UCB1 (Upper Confidence Bound)
- Thompson Sampling (Bayesian Bandit)

## Problems

- Multi-Armed Bandit


Note: some of this material was sourced from the course "Artificial Intelligence: Reinforcement Learning in Python" by "Lazy Programmer Inc".
