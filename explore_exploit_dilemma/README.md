# Explore-Exploit Dilemma

- Epsilon-greedy
- Optimistic Initial Values
- UCB1 (Upper Confidence Bound)
- Thompson Sampling (Bayesian Bandit)

## Problems

- Multi-Armed Bandit
